# This is an example which shows a potential problem with frequent reload of nginx process.
# Frequent reloading might leave old nginx workers running for an extended period of time.

# The use of upstream_conf API in NGINX Plus reduces the frequency of reloads.

# Usage:

# Run nginx with this configuration file, then see the process list:
# ps ax | grep nginx

# Run several requests through this server. Every request will take about a minute:
# curl -v http://localhost/ & curl -v http://localhost/ & curl -v http://localhost/ & curl -v http://localhost/

# While the requests are processing reload nginx:
# nginx -s reload

# Immediately check the processes again:
# ps ax | grep nginx

# You will see a number of processes in "shutting down" state:
#  1304 ?        S      0:00  \_ nginx: worker process is shutting down

# See more detailis in NGINX Blog: https://www.nginx.com/blog/

user nginx;
events { worker_connections 2014; }
worker_processes 8;

http {
	default_type text/plain;
	tcp_nodelay on;
	server {
		listen 8081;
		return 200 "Server $server_addr:$server_port\n\nTime: $time_local\n\n
Syntax:		proxy_limit_rate rate;
Default:	proxy_limit_rate 0;
Context:	http, server, location

This directive appeared in version 1.7.7.
Limits the speed of reading the response
from the proxied server.
The rate is specified in bytes per second.
The zero value disables rate limiting.
The limit is set per a request,
and so if nginx simultaneously opens
two connections to the proxied server,
the overall rate will be twice as much
as the specified limit. The limitation
works only if buffering of responses
from the proxied server is enabled.
	";
	}
	upstream backend {
		zone backend 64k;
		server 127.0.0.1:8081;
	}
	server {
		listen 80 reuseport; # Hint: try this configuration with and without reuseport parameter.
		limit_rate 20; # Limiting the rate to 20 bytes per second in order to imitate long lasting active connections.
		location / {
			proxy_pass http://backend;
		}
	}
}


